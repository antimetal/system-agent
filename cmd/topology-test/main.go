// Copyright Antimetal, Inc. All rights reserved.
//
// Use of this source code is governed by a source available license that can be found in the
// LICENSE file or at:
// https://polyformproject.org/wp-content/uploads/2020/06/PolyForm-Shield-1.0.0.txt

package main

import (
	"context"
	"fmt"
	"os"
	"time"

	"github.com/antimetal/agent/internal/hardware"
	"github.com/antimetal/agent/internal/runtime"
	"github.com/antimetal/agent/internal/runtime/tracker"
	"github.com/antimetal/agent/pkg/containers"
	"github.com/antimetal/agent/pkg/performance"
	"github.com/antimetal/agent/pkg/resource/store"
	"github.com/go-logr/logr"
	"github.com/go-logr/zapr"
	"go.uber.org/zap"
)

func main() {
	// Setup logging
	zapLog, _ := zap.NewDevelopment()
	logger := zapr.NewLogger(zapLog)

	fmt.Println("=== Antimetal Agent Container-Process-Hardware Topology Test ===")
	fmt.Println()

	// Test 1: Container Discovery
	fmt.Println("1. Testing Container Discovery...")
	testContainerDiscovery(logger)
	fmt.Println()

	// Test 2: Hardware Discovery
	fmt.Println("2. Testing Hardware Discovery...")
	testHardwareDiscovery(logger)
	fmt.Println()

	// Test 3: Runtime Manager Integration
	fmt.Println("3. Testing Runtime Manager Integration...")
	testRuntimeManagerIntegration(logger)
	fmt.Println()

	// Test 4: Full Topology Discovery
	fmt.Println("4. Testing Full Topology Discovery...")
	testFullTopologyDiscovery(logger)
	fmt.Println()

	fmt.Println("=== All Tests Completed ===")
}

func testContainerDiscovery(logger logr.Logger) {
	// Test container discovery across different runtime paths
	runtimePaths := []string{
		"/var/lib/docker/containers",
		"/run/containerd/io.containerd.runtime.v2.task",
		"/var/lib/containers/storage/overlay-containers",
		"/run/crio/containers",
	}

	discovery := containers.NewDiscovery("/sys/fs/cgroup")

	// Detect cgroup version first
	cgroupVersion, err := discovery.DetectCgroupVersion()
	if err != nil {
		fmt.Printf("   ‚ùå Failed to detect cgroup version: %v\n", err)
		return
	}
	fmt.Printf("   üîç Detected cgroup version: %d\n", cgroupVersion)

	// Test memory subsystem discovery
	containers, err := discovery.DiscoverContainers("memory", cgroupVersion)
	if err != nil {
		fmt.Printf("   ‚ùå Container discovery failed: %v\n", err)
		return
	}

	fmt.Printf("   ‚úÖ Discovered %d containers\n", len(containers))
	
	// Show details of discovered containers
	runtimeCounts := make(map[string]int)
	cgroupVersionCounts := make(map[string]int)
	
	for _, container := range containers {
		runtimeCounts[container.Runtime]++
		cgroupVersionCounts[fmt.Sprintf("v%d", container.CgroupVersion)]++
		
		if len(container.ID) >= 12 {
			fmt.Printf("   üì¶ Container: %s (Runtime: %s, Cgroup: v%d)\n",
				container.ID[:12], // Show first 12 chars
				container.Runtime,
				container.CgroupVersion)
		} else {
			fmt.Printf("   üì¶ Container: %s (Runtime: %s, Cgroup: v%d)\n",
				container.ID,
				container.Runtime,
				container.CgroupVersion)
		}
	}
	
	fmt.Printf("   üìä Runtime distribution: %+v\n", runtimeCounts)
	fmt.Printf("   üìä Cgroup version distribution: %+v\n", cgroupVersionCounts)

	// Test specific runtime paths
	fmt.Println("   üîç Testing runtime path detection:")
	for _, path := range runtimePaths {
		if _, err := os.Stat(path); err == nil {
			fmt.Printf("   ‚úÖ Found runtime path: %s\n", path)
		} else {
			fmt.Printf("   ‚ö†Ô∏è  Runtime path not found: %s\n", path)
		}
	}
}

func testHardwareDiscovery(logger logr.Logger) {
	// Create performance manager for hardware discovery
	config := performance.DefaultCollectionConfig()
	config.HostProcPath = "/proc"
	config.HostSysPath = "/sys"
	config.HostDevPath = "/dev"

	perfManager, err := performance.NewManager(performance.ManagerOptions{
		Logger:   logger,
		NodeName: "test-node",
		Config:   config,
	})
	if err != nil {
		fmt.Printf("   ‚ùå Failed to create performance manager: %v\n", err)
		return
	}

	// Create in-memory store for testing
	store, err := store.New("")
	if err != nil {
		fmt.Printf("   ‚ùå Failed to create resource store: %v\n", err)
		return
	}
	defer store.Close()

	// Create hardware manager
	hwManager, err := hardware.NewManager(logger, hardware.ManagerConfig{
		Store:              store,
		PerformanceManager: perfManager,
		UpdateInterval:     30 * time.Second,
	})
	if err != nil {
		fmt.Printf("   ‚ùå Failed to create hardware manager: %v\n", err)
		return
	}

	// Start hardware discovery
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	if err := hwManager.Start(ctx); err != nil {
		fmt.Printf("   ‚ùå Hardware discovery failed: %v\n", err)
		return
	}

	// Force an update to collect hardware information
	if err := hwManager.ForceUpdate(); err != nil {
		fmt.Printf("   ‚ùå Hardware update failed: %v\n", err)
		return
	}

	fmt.Printf("   ‚úÖ Hardware discovery completed successfully\n")
	fmt.Printf("   üìä Last update: %v\n", hwManager.GetLastUpdateTime())

	// Stop hardware manager
	if err := hwManager.Stop(); err != nil {
		fmt.Printf("   ‚ö†Ô∏è  Error stopping hardware manager: %v\n", err)
	}
}

func testRuntimeManagerIntegration(logger logr.Logger) {
	// Create performance manager
	config := performance.DefaultCollectionConfig()
	config.HostProcPath = "/proc"
	config.HostSysPath = "/sys"
	config.HostDevPath = "/dev"

	perfManager, err := performance.NewManager(performance.ManagerOptions{
		Logger:   logger,
		NodeName: "test-node",
		Config:   config,
	})
	if err != nil {
		fmt.Printf("   ‚ùå Failed to create performance manager: %v\n", err)
		return
	}

	// Create in-memory store
	store, err := store.New("")
	if err != nil {
		fmt.Printf("   ‚ùå Failed to create resource store: %v\n", err)
		return
	}
	defer store.Close()

	// Create runtime manager
	rtManager, err := runtime.NewManager(
		logger,
		runtime.ManagerConfig{
			Store:              store,
			PerformanceManager: perfManager,
			UpdateInterval:     10 * time.Second,
			TrackerConfig: tracker.TrackerConfig{
				Mode:       tracker.TrackerModeAuto,
				CgroupPath: "/sys/fs/cgroup",
			},
		},
	)
	if err != nil {
		fmt.Printf("   ‚ùå Failed to create runtime manager: %v\n", err)
		return
	}

	// Start runtime manager (it blocks, so run in goroutine)
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	// Run the runtime manager in a goroutine since it blocks
	go func() {
		if err := rtManager.Start(ctx); err != nil {
			fmt.Printf("   ‚ùå Runtime manager start failed: %v\n", err)
		}
	}()

	// Let it run for a bit to collect data
	fmt.Printf("   ‚è≥ Collecting runtime data for 5 seconds...\n")
	time.Sleep(5 * time.Second)

	fmt.Printf("   ‚úÖ Runtime manager integration test completed\n")

	// Stop runtime manager by canceling context
	cancel()
}

func testFullTopologyDiscovery(logger logr.Logger) {
	fmt.Printf("   üîÑ Running full container-process-hardware topology discovery...\n")
	
	// Create performance manager
	config := performance.DefaultCollectionConfig()
	config.HostProcPath = "/proc"
	config.HostSysPath = "/sys"
	config.HostDevPath = "/dev"

	perfManager, err := performance.NewManager(performance.ManagerOptions{
		Logger:   logger,
		NodeName: "topology-test-node",
		Config:   config,
	})
	if err != nil {
		fmt.Printf("   ‚ùå Performance manager creation failed: %v\n", err)
		return
	}

	// Create store
	store, err := store.New("")
	if err != nil {
		fmt.Printf("   ‚ùå Store creation failed: %v\n", err)
		return
	}
	defer store.Close()

	// Create hardware manager
	hwManager, err := hardware.NewManager(logger, hardware.ManagerConfig{
		Store:              store,
		PerformanceManager: perfManager,
		UpdateInterval:     30 * time.Second,
	})
	if err != nil {
		fmt.Printf("   ‚ùå Hardware manager creation failed: %v\n", err)
		return
	}

	// Create runtime manager
	rtManager, err := runtime.NewManager(
		logger,
		runtime.ManagerConfig{
			Store:              store,
			PerformanceManager: perfManager,
			UpdateInterval:     10 * time.Second,
			TrackerConfig: tracker.TrackerConfig{
				Mode:       tracker.TrackerModeAuto,
				CgroupPath: "/sys/fs/cgroup",
			},
		},
	)
	if err != nil {
		fmt.Printf("   ‚ùå Runtime manager creation failed: %v\n", err)
		return
	}

	// Start both managers
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	if err := hwManager.Start(ctx); err != nil {
		fmt.Printf("   ‚ùå Hardware manager start failed: %v\n", err)
		return
	}

	// Run the runtime manager in a goroutine since it blocks
	go func() {
		if err := rtManager.Start(ctx); err != nil {
			fmt.Printf("   ‚ùå Runtime manager start failed: %v\n", err)
		}
	}()

	// Let them collect data
	fmt.Printf("   ‚è≥ Collecting topology data for 10 seconds...\n")
	time.Sleep(10 * time.Second)

	// Force updates to ensure data collection
	if err := hwManager.ForceUpdate(); err != nil {
		fmt.Printf("   ‚ö†Ô∏è  Hardware update failed: %v\n", err)
	}

	fmt.Printf("   ‚úÖ Full topology discovery completed successfully!\n")
	fmt.Printf("   üìä Hardware last update: %v\n", hwManager.GetLastUpdateTime())

	// Cleanup - context cancellation will stop the runtime manager
	// Hardware manager has its own Stop() method
	if err := hwManager.Stop(); err != nil {
		fmt.Printf("   ‚ö†Ô∏è  Error stopping hardware manager: %v\n", err)
	}
}